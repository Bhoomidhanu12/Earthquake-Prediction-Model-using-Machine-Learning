**Earthquake Prediction Model with Machine Learning
**Project Abstract:**
This project focuses on building a machine learning-based model to predict earthquake characteristics such as magnitude and depth using historical seismic data. By leveraging advanced neural networks and data preprocessing techniques, the model aims to enhance earthquake prediction accuracy, contributing to disaster preparedness and risk mitigation.
**Objectives:**
To preprocess and analyze earthquake datasets to extract meaningful features.
To convert date-time data into machine-readable timestamps for model input.
To visualize earthquake data geographically to identify patterns.
To design, train, and validate a neural network for predicting earthquake magnitude and depth.
To evaluate the model’s performance and optimize hyperparameters for improved accuracy.
Tools and Technologies:
Programming Language: Python

Libraries: Pandas, NumPy, Matplotlib, Keras (TensorFlow backend), scikit-learn

Data Visualization: Basemap for mapping earthquake locations

Dataset: Historical earthquake data including date, time, latitude, longitude, depth, and magnitudeMethodology:
**Data Collection & Preprocessing:**
Loaded historical earthquake data with features like date, time, location (latitude, longitude), depth, and magnitude.
Converted date and time into Unix timestamps to use as numerical inputs for the model.
Cleaned the dataset by removing invalid records.
**Data Visualization:**
Mapped earthquake occurrences globally using Basemap to identify seismic hotspots.
**Feature Selection:**
Used timestamp, latitude, and longitude as input features (X).
Used magnitude and depth as target variables (y).
**Data Splitting:**
Split the dataset into training (80%) and testing (20%) sets.
**Model Building:**
Constructed a neural network with three dense layers using Keras.
Experimented with activation functions, optimizers, batch sizes, and epochs to find the best model through Grid Search.
**Training & Evaluation:**
Trained the model on the training set and validated on the test set.
Achieved test accuracy of approximately 92%, indicating strong predictive performance.
**Challenges:**
Earthquake data is complex and not strictly periodic, making prediction inherently difficult.
Limited available features; external geological factors could improve accuracy but were not included.
Conversion and handling of time-series data required careful preprocessing.
**Future Work:**
Integrate additional features like seismic wave readings or geological data.
Use more sophisticated models (e.g., LSTM for time-series prediction) to improve temporal predictions.
Deploy a real-time prediction dashboard with live seismic data inputs.
**Conclusion:**
This project successfully demonstrates the potential of machine learning models to predict earthquake parameters with reasonable accuracy. While earthquake prediction remains a challenging task, this approach highlights the value of data-driven methods in improving early warning systems.
Working Project In Jupyter notebook
I will start this task to create a model for earthquake prediction by importing the necessary python libraries:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
Now let’s load and read the dataset. The dataset that I am using here can be easily downloaded here:database.csv
data = pd.read_csv("database.csv")
data.columns
Now let’s see the main characteristics of earthquake data and create an object of these characteristics, namely, date, time, latitude, longitude, depth, magnitude:
data = data[['Date', 'Time', 'Latitude', 'Longitude', 'Depth', 'Magnitude']]
data.head()
Since the data is random, so we need to scale it based on the model inputs. In this, we convert the given date and time to Unix time which is in seconds and a number. This can be easily used as an entry for the network we have built:
import datetime
import time
timestamp = []
for d, t in zip(data['Date'], data['Time']):
    try:
        ts = datetime.datetime.strptime(d+' '+t, '%m/%d/%Y %H:%M:%S')
        timestamp.append(time.mktime(ts.timetuple()))
    except ValueError:
        # print('ValueError')
        timestamp.append('ValueError')
timeStamp = pd.Series(timestamp)
data['Timestamp'] = timeStamp.values
final_data = data.drop(['Date', 'Time'], axis=1)
Data Visualization
Now, before we create the earthquake prediction model, let’s visualize the data on a world map that shows a clear representation of where the earthquake frequency will be more:

from mpl_toolkits.basemap import Basemap

m = Basemap(projection='mill',llcrnrlat=-80,urcrnrlat=80, llcrnrlon=-180,urcrnrlon=180,lat_ts=20,resolution='c')

longitudes = data["Longitude"].tolist()
latitudes = data["Latitude"].tolist()
#m = Basemap(width=12000000,height=9000000,projection='lcc',
            #resolution=None,lat_1=80.,lat_2=55,lat_0=80,lon_0=-107.)
x,y = m(longitudes,latitudes)

fig = plt.figure(figsize=(12,10))
plt.title("All affected areas")
m.plot(x, y, "o", markersize = 2, color = 'blue')
m.drawcoastlines()
m.fillcontinents(color='coral',lake_color='aqua')
m.drawmapboundary()
m.drawcountries()
plt.show()
Now, to create the earthquake prediction model, we need to divide the data into Xs and ys which respectively will be entered into the model as inputs to receive the output from the model.

Here the inputs are TImestamp, Latitude and Longitude and the outputs are Magnitude and Depth. I’m going to split the xs and ys into train and test with validation. The training set contains 80% and the test set contains 20%:

X = final_data[['Timestamp', 'Latitude', 'Longitude']]
y = final_data[['Magnitude', 'Depth']]
from sklearn.cross_validation import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
print(X_train.shape, X_test.shape, y_train.shape, X_test.shape)
Now I will create a neural network to fit the data from the training set. Our neural network will consist of three dense layers each with 16, 16, 2 nodes and reread. Relu and softmax will be used as activation functions:

from keras.models import Sequential
from keras.layers import Dense

def create_model(neurons, activation, optimizer, loss):
    model = Sequential()
    model.add(Dense(neurons, activation=activation, input_shape=(3,)))
    model.add(Dense(neurons, activation=activation))
    model.add(Dense(2, activation='softmax'))
    
    model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])
    
    return model
Now I’m going to define the hyperparameters with two or more options to find the best fit:

from keras.wrappers.scikit_learn import KerasClassifier

model = KerasClassifier(build_fn=create_model, verbose=0)

# neurons = [16, 64, 128, 256]
neurons = [16]
# batch_size = [10, 20, 50, 100]
batch_size = [10]
epochs = [10]
# activation = ['relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear', 'exponential']
activation = ['sigmoid', 'relu']
# optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']
optimizer = ['SGD', 'Adadelta']
loss = ['squared_hinge']

param_grid = dict(neurons=neurons, batch_size=batch_size, epochs=epochs,activation=activation, optimizer=optimizer, loss=loss)
Now we need to find the best fit of the above model and get the mean test score and standard deviation of the best fit model:


grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)
grid_result = grid.fit(X_train, y_train)

print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']
for mean, stdev, param in zip(means, stds, params):
    print("%f (%f) with: %r" % (mean, stdev, param))
In the step below, the best-fit parameters are used for the same model to calculate the score with the training data and the test data:
model = Sequential()
model.add(Dense(16, activation='relu', input_shape=(3,)))
model.add(Dense(16, activation='relu'))
model.add(Dense(2, activation='softmax'))

model.compile(optimizer='SGD', loss='squared_hinge', metrics=['accuracy'])
model.fit(X_train, y_train, batch_size=10, epochs=20, verbose=1, validation_data=(X_test, y_test))

[test_loss, test_acc] = model.evaluate(X_test, y_test)
print("Evaluation result on Test Data : Loss = {}, accuracy = {}".format(test_loss, test_acc))
So we can see in the above output that our neural network model for earthquake prediction performs well. I hope you liked this article on how to create an earthquake prediction model with machine learning and the Python programming language.

final_data = final_data[final_data.Timestamp != 'ValueError']
final_data.head()
